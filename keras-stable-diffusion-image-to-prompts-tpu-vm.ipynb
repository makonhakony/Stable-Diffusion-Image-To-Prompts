{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About Notebook\n\nIt is basic starter notebook for Stable-Diffusion Image-to-Prompt, written in `keras`, `keras-cv`, and `transformer` from huggingface. It contains both **training code** and **inference code**. Please note, the training code is configured on **TPU-VM**, otherwise on **GPU**.","metadata":{}},{"cell_type":"code","source":"# set True for 'Inference' on GPU (turn off the internet)\n# set False for 'Training' on TPU-VM (turn on the internet)\nSUBMIT = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nimport logging\nfrom IPython.display import clear_output\nwarnings.filterwarnings('ignore')\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nlogging.disable(logging.WARNING)\n\n\nif SUBMIT:\n    !pip install --no-deps ../input/keras-cv/keras_cv-0.4.2-py3-none-any.whl\nelse:\n    !pip install -U -q scikit-learn\n    !pip install -U -q transformers\n    \nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd \nimport warnings\nimport random\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.optimizers import schedules\nfrom tensorflow.python.client import device_lib\n\ntry:\n    import keras_cv\n    from keras_cv.layers import RandomBrightness\n    from keras_cv.layers import RandomChannelShift\n    from keras_cv.layers import RandomFlip\nexcept:\n    from keras.layers import RandomFlip\n\nimport transformers\nfrom transformers import AutoConfig\nfrom transformers import TFBertTokenizer\nfrom transformers import TFAutoModel\nfrom transformers import ViTFeatureExtractor\nfrom transformers import TFViTModel\ntransformers.logging.disable_progress_bar()\n\ntf.__version__, transformers.__version__","metadata":{"papermill":{"duration":11.202741,"end_time":"2023-03-18T22:39:34.82395","exception":false,"start_time":"2023-03-18T22:39:23.621209","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Devices","metadata":{"papermill":{"duration":0.004167,"end_time":"2023-03-18T22:39:34.832573","exception":false,"start_time":"2023-03-18T22:39:34.828406","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if SUBMIT:\n    physical_devices = tf.config.list_physical_devices('GPU')\n    tf.config.optimizer.set_jit(True)\n    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n    [tf.config.experimental.set_memory_growth(pd, True) for pd in physical_devices]\n    strategy = tf.distribute.MirroredStrategy()\nelse:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n    strategy = tf.distribute.TPUStrategy(tpu)\n\n    \nseed = 80\ninput_size = 224\nbatch_size = 40 * strategy.num_replicas_in_sync\nnum_epochs = 14\nkeras.utils.set_random_seed(seed)","metadata":{"papermill":{"duration":6.409012,"end_time":"2023-03-18T22:39:41.245804","exception":false,"start_time":"2023-03-18T22:39:34.836792","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data [Training]","metadata":{"papermill":{"duration":0.004066,"end_time":"2023-03-18T22:39:41.254555","exception":false,"start_time":"2023-03-18T22:39:41.250489","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diffusiondb-data-cleansing/diffusiondb.csv')\ntrn_df, val_df = train_test_split(\n    df, test_size=0.1, random_state=seed\n)\ntrn_df.shape, val_df.shape","metadata":{"papermill":{"duration":0.697233,"end_time":"2023-03-18T22:39:41.956087","exception":false,"start_time":"2023-03-18T22:39:41.258854","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get max sequence\ntrn_df[\"prompt\"].apply(lambda x: len(x.split())).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader [Training]","metadata":{"papermill":{"duration":0.004263,"end_time":"2023-03-18T22:39:41.965431","exception":false,"start_time":"2023-03-18T22:39:41.961168","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_id = 'sentence-transformers/all-MiniLM-L6-v2'\ntokenizer = TFBertTokenizer.from_pretrained(model_id)\n\ndef read_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_png(image, 3)\n    image = tf.image.resize(image, (input_size, input_size))\n    return image\n\ndef batch_tokenize(prompt):\n    tokenized = tokenizer(\n        prompt, \n        padding=\"max_length\", \n        truncation=True, \n        max_length=512\n    )\n    return tokenized","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataloader(\n    image_paths, \n    prompts, \n    shuffle=True, \n    repeat=True, \n    batch_size=1,\n):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, prompts))\n    dataset = dataset.map(\n        lambda x, y: (read_image(x), y),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    dataset = dataset.batch(\n        batch_size, drop_remainder=True\n    )\n\n    dataset = dataset.map(\n        lambda x, y: (x, (batch_tokenize(y))),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    \n    if shuffle:\n        dataset = dataset.shuffle(\n            batch_size * 8, reshuffle_each_iteration = False\n        )\n    \n    if repeat:\n        dataset = dataset.repeat()\n        \n    return dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"papermill":{"duration":0.015733,"end_time":"2023-03-18T22:39:41.985631","exception":false,"start_time":"2023-03-18T22:39:41.969898","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = dataloader(\n    trn_df[\"filepath\"].values, \n    trn_df['prompt'].values, \n    shuffle=True, \n    repeat=False,\n    batch_size=batch_size\n)\n\nvalid_ds = dataloader(\n    val_df[\"filepath\"].values, \n    val_df['prompt'].values, \n    shuffle=False, \n    repeat=False, \n    batch_size=batch_size\n)","metadata":{"papermill":{"duration":0.202647,"end_time":"2023-03-18T22:39:42.192644","exception":false,"start_time":"2023-03-18T22:39:41.989997","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"execution":{"iopub.execute_input":"2023-03-17T18:01:43.721927Z","iopub.status.busy":"2023-03-17T18:01:43.721406Z","iopub.status.idle":"2023-03-17T18:01:43.728693Z","shell.execute_reply":"2023-03-17T18:01:43.727048Z","shell.execute_reply.started":"2023-03-17T18:01:43.721886Z"},"papermill":{"duration":0.00467,"end_time":"2023-03-18T22:39:42.202125","exception":false,"start_time":"2023-03-18T22:39:42.197455","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def preprocess(x):\n    x = keras.layers.Rescaling(scale=1./127.5, offset=-1.0)(x)\n    x = keras.layers.Permute(dims=(3, 1, 2))(x)\n    return x\n    \ndef augment(x):\n    try:\n        pipeline = keras_cv.layers.RandomChoice(\n            layers=[\n                RandomFlip(\"horizontal\")\n            ],\n            auto_vectorize=True\n        )\n    except:\n        pipeline = keras.Sequential(\n            [\n                keras.layers.RandomFlip(\"horizontal\")\n            ]\n        )\n    return pipeline(x)","metadata":{"papermill":{"duration":0.013431,"end_time":"2023-03-18T22:39:42.219958","exception":false,"start_time":"2023-03-18T22:39:42.206527","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(mode='inference'):\n    input = keras.Input(shape=(input_size, input_size, 3))\n    x = augment(input)\n    x = preprocess(x)\n\n    # vit model\n    if mode=='inference':\n        config =  AutoConfig.from_pretrained(\n            '/kaggle/input/cmp-stablediffusion-imgtopt', \n            local_files_only=True\n        )\n        hf_model = TFViTModel.from_config(config)\n        x = hf_model(x)\n    else:\n        x = TFViTModel.from_pretrained(\n            'google/vit-base-patch16-224'\n        )(x)\n    x = keras.layers.Lambda(lambda v: v[:, 0])(x.last_hidden_state)\n    \n    # output\n    output = keras.layers.Dense(\n        384, activation=None, dtype=tf.float32\n    )(x)\n\n    model = keras.Model(input, output)\n    return model","metadata":{"papermill":{"duration":0.013599,"end_time":"2023-03-18T22:39:42.238042","exception":false,"start_time":"2023-03-18T22:39:42.224443","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sentence Transformer (all-MiniLM-L6-v2)**\n\nIt will be run on inside the model.","metadata":{"papermill":{"duration":0.004217,"end_time":"2023-03-18T22:39:42.246935","exception":false,"start_time":"2023-03-18T22:39:42.242718","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ref. https://www.philschmid.de/tensorflow-sentence-transformers\nclass TFSentenceTransformer(keras.layers.Layer):\n    def __init__(self,  model_id, **kwargs):\n        super().__init__(**kwargs)\n        self.st_model = TFAutoModel.from_pretrained(model_id, **kwargs)\n\n    def call(self, inputs, normalize=True):\n        model_output = self.st_model(inputs)\n        embeddings = self.mean_pooling(\n            model_output, inputs[\"attention_mask\"]\n        )\n        if normalize:\n            embeddings = self.normalize(embeddings)\n        return embeddings\n\n    def mean_pooling(self, model_output, attention_mask):\n        token_embeddings = model_output[0]\n        input_mask_expanded = tf.cast(\n            tf.broadcast_to(\n                tf.expand_dims(attention_mask, -1), \n                tf.shape(token_embeddings)\n            ),\n            token_embeddings.dtype\n        )\n        token_mask = tf.reduce_sum(\n            token_embeddings * input_mask_expanded, axis=1\n        )\n        mask_clip = tf.clip_by_value(\n            tf.reduce_sum(input_mask_expanded, axis=1), \n            1e-9, \n            tf.float32.max\n        )\n        return token_mask / mask_clip\n        \n    def normalize(self, embeddings):\n        embeddings, _ = tf.linalg.normalize(\n            embeddings, 2, axis=1\n        )\n        return embeddings","metadata":{"papermill":{"duration":0.016905,"end_time":"2023-03-18T22:39:42.268476","exception":false,"start_time":"2023-03-18T22:39:42.251571","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextToEmbedding(keras.Model):\n    '''Transform the text/prompt gt to 384-D embedding with sentence transformer.\n    '''\n    def __init__(self, model, **kwargs):\n        super().__init__(**kwargs)\n        self.model = model \n    \n    def call(self, inputs):\n        return self.model(inputs)\n    \n    def train_step(self, data):\n        x, y = data\n        y = tfst_model(y, normalize=False)\n        return super().train_step((x, y))\n    \n    def test_step(self, data):\n        x, y = data\n        y = tfst_model(y, normalize=False)\n        return super().test_step((x, y))\n    \n    # kaggle.com/code/ipythonx/keras-rsna-breast-cancer-detection\n    def save_weights(\n        self, filepath, overwrite=True, save_format=None, options=None\n    ):\n        # Overriding this method will allow us to use the `ModelCheckpoint`\n        self.model.save_weights(\n            filepath=filepath,\n            overwrite=overwrite,\n            save_format=save_format,\n            options=options,\n        )\n        \n    def save(\n        self, filepath, overwrite=True, include_optimizer=True, \n        save_format=None, signatures=None, options=None\n    ):\n        # Overriding this method will allow us to use the `ModelCheckpoint`\n        self.model.save(\n            filepath=filepath,\n            overwrite=overwrite,\n            save_format=save_format,\n            options=options,\n            include_optimizer=include_optimizer,\n            signatures=signatures\n        )","metadata":{"papermill":{"duration":0.017489,"end_time":"2023-03-18T22:39:42.290472","exception":false,"start_time":"2023-03-18T22:39:42.272983","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://stackoverflow.com/a/44933346/9215780\ncosine_similarity_loss = keras.losses.CosineSimilarity(\n    reduction='none'\n)\n\ndef CosineEmbeddingLoss(margin=0., target=1):\n    def cosine_embedding_loss_fn(input_one, input_two):\n        similarity = - cosine_similarity_loss(input_one, input_two)\n        return tf.reduce_mean(\n            tf.where(\n                tf.equal(target, 1),\n                1. - similarity,\n                tf.maximum(\n                    tf.zeros_like(similarity), similarity - margin\n                )\n            )\n        )\n    return cosine_embedding_loss_fn","metadata":{"papermill":{"duration":0.014447,"end_time":"2023-03-18T22:39:42.309438","exception":false,"start_time":"2023-03-18T22:39:42.294991","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\nwith strategy.scope():\n    if SUBMIT:\n        model = get_model(mode='inference')\n        model.load_weights(\n            '/kaggle/input/cmp-stablediffusion-imgtopt/model.02-0.533.h5'\n        )\n        model.compile(jit_compile=True)\n        model.trainable = False\n    else:\n        # token to text-embedding\n        tfst_model = TFSentenceTransformer(model_id)\n        tfst_model.trainable = False\n\n        model = get_model(mode='training')\n        model = TextToEmbedding(model)\n\n        model.compile(\n            optimizer='Adamax',\n            loss=CosineEmbeddingLoss(margin=0., target=1),\n            metrics=[metrics.CosineSimilarity(name='cos')],\n        )\n        model.build(\n            input_shape=(None, input_size, input_size, 3)\n        )\n    \nclear_output()","metadata":{"papermill":{"duration":25.308905,"end_time":"2023-03-18T22:40:07.632154","exception":false,"start_time":"2023-03-18T22:39:42.323249","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keras.backend.clear_session()\n# with strategy.scope():\n#     processor = AutoProcessor.from_pretrained(\n#         \"/kaggle/input/salesforceblip-image-caption\"\n#     )\n#     model = TFBlipForConditionalGeneration.from_pretrained(\n#         \"/kaggle/input/salesforceblip-image-caption\"\n#     )\n#     model.compile(\n#         jit_compile=True\n#     )\n#     model.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary(\n    expand_nested=True, \n    line_length=100, \n    show_trainable=True\n)","metadata":{"papermill":{"duration":0.108371,"end_time":"2023-03-18T22:40:07.746667","exception":false,"start_time":"2023-03-18T22:40:07.638296","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SUBMIT:\n    training_log = pd.read_csv('/kaggle/input/cmp-stablediffusion-imgtopt/training_log.csv')\n    display(training_log.head())\nelse:\n    model.fit(\n        train_ds, \n        validation_data=valid_ds, \n        epochs=num_epochs,\n        callbacks=[\n            callbacks.ModelCheckpoint(\n                filepath='model.{epoch:02d}-{val_cos:.3f}.h5',\n                monitor='val_cos',\n                mode='max',\n                save_best_only=True\n            ),\n            callbacks.CSVLogger('training_log.csv')\n        ]\n    )","metadata":{"papermill":{"duration":20111.777777,"end_time":"2023-03-19T04:15:19.532497","exception":false,"start_time":"2023-03-18T22:40:07.75472","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data [Inference]","metadata":{}},{"cell_type":"code","source":"comp_path = '/kaggle/input/stable-diffusion-image-to-prompts'\nimag_path = glob.glob(f'{comp_path}/images/*.png')\nimages = os.listdir(os.path.join(comp_path, 'images'))\nimgIds = [i.split('.')[0] for i in images]\n\nEMBEDDING_LENGTH = 384\neIds = list(range(EMBEDDING_LENGTH))\n\nimgId_eId = [\n    '_'.join(map(str, i)) for i in zip(\n        np.repeat(imgIds, EMBEDDING_LENGTH),\n        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))\n]","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader [Inference]","metadata":{}},{"cell_type":"code","source":"def dataloader(\n    image_paths, batch_size=1\n):\n    dataset = tf.data.Dataset.from_tensor_slices(\n        (image_paths)\n    )\n    dataset = dataset.map(read_image, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    return dataset.prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds = dataloader(\n    imag_path, batch_size=batch_size\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"prompt_embeddings = model.predict(test_ds)\nprompt_embeddings = np.vstack(prompt_embeddings).flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(\n    index=imgId_eId,\n    data=prompt_embeddings,\n    columns=['val']\n).rename_axis('imgId_eId')\nsubmission.to_csv('submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}